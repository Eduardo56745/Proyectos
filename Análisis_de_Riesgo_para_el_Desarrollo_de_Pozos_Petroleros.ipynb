{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de Riesgo para el Desarrollo de Pozos Petroleros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El proyecto tiene como objetivo ayudar a la empresa OilyGiant a elegir la mejor región para abrir 200 nuevos pozos de petróleo. Para esto, se analizan tres regiones diferentes, basándose en datos como la cantidad de petróleo que se podría extraer de cada pozo.\n",
    "\n",
    "### Primero, se crea un modelo que predice cuánto petróleo podría haber en los nuevos pozos. Luego, se seleccionan los pozos con el mayor potencial y se calcula el beneficio de abrirlos en cada región. Finalmente, se analiza el riesgo de perder dinero usando una técnica llamada bootstrapping, que ayuda a ver diferentes escenarios posibles.\n",
    "\n",
    "### El objetivo es encontrar cuál de las tres regiones ofrece el mayor beneficio y menor riesgo para la empresa, y así recomendar la mejor opción para abrir los pozos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descargar y preparar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías necesarias\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos de los tres archivos csv en tres dataframes\n",
    "\n",
    "data_0 = pd.read_csv('geo_data_0.csv')\n",
    "\n",
    "data_1 = pd.read_csv('geo_data_1.csv')\n",
    "\n",
    "data_2 = pd.read_csv('geo_data_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id        f0        f1        f2     product\n",
      "0  txEyH  0.705745 -0.497823  1.221170  105.280062\n",
      "1  2acmU  1.334711 -0.340164  4.365080   73.037750\n",
      "2  409Wp  1.022732  0.151990  1.419926   85.265647\n",
      "3  iJLyR -0.032172  0.139033  2.978566  168.620776\n",
      "4  Xdl7t  1.988431  0.155413  4.751769  154.036647\n",
      "\n",
      "      id         f0         f1        f2     product\n",
      "0  kBEdx -15.001348  -8.276000 -0.005876    3.179103\n",
      "1  62mP7  14.272088  -3.475083  0.999183   26.953261\n",
      "2  vyE1P   6.263187  -5.948386  5.001160  134.766305\n",
      "3  KcrkZ -13.081196 -11.506057  4.999415  137.945408\n",
      "4  AHL4O  12.702195  -8.147433  5.004363  134.766305\n",
      "\n",
      "      id        f0        f1        f2     product\n",
      "0  fwXo0 -1.146987  0.963328 -0.828965   27.758673\n",
      "1  WJtFt  0.262778  0.269839 -2.530187   56.069697\n",
      "2  ovLUW  0.194587  0.289035 -5.586433   62.871910\n",
      "3  q6cA6  2.236060 -0.553760  0.930038  114.572842\n",
      "4  WPMUX -0.515993  1.716266  5.899011  149.600746\n"
     ]
    }
   ],
   "source": [
    "#Imprimimos los primeros 5 registros de cada dataframe\n",
    "\n",
    "print(data_0.head())\n",
    "print()\n",
    "print(data_1.head())\n",
    "print()\n",
    "print(data_2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "None\n",
      "                  f0             f1             f2        product\n",
      "count  100000.000000  100000.000000  100000.000000  100000.000000\n",
      "mean        0.500419       0.250143       2.502647      92.500000\n",
      "std         0.871832       0.504433       3.248248      44.288691\n",
      "min        -1.408605      -0.848218     -12.088328       0.000000\n",
      "25%        -0.072580      -0.200881       0.287748      56.497507\n",
      "50%         0.502360       0.250252       2.515969      91.849972\n",
      "75%         1.073581       0.700646       4.715088     128.564089\n",
      "max         2.362331       1.343769      16.003790     185.364347\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "None\n",
      "                  f0             f1             f2        product\n",
      "count  100000.000000  100000.000000  100000.000000  100000.000000\n",
      "mean        1.141296      -4.796579       2.494541      68.825000\n",
      "std         8.965932       5.119872       1.703572      45.944423\n",
      "min       -31.609576     -26.358598      -0.018144       0.000000\n",
      "25%        -6.298551      -8.267985       1.000021      26.953261\n",
      "50%         1.153055      -4.813172       2.011479      57.085625\n",
      "75%         8.621015      -1.332816       3.999904     107.813044\n",
      "max        29.421755      18.734063       5.019721     137.945408\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "None\n",
      "                  f0             f1             f2        product\n",
      "count  100000.000000  100000.000000  100000.000000  100000.000000\n",
      "mean        0.002023      -0.002081       2.495128      95.000000\n",
      "std         1.732045       1.730417       3.473445      44.749921\n",
      "min        -8.760004      -7.084020     -11.970335       0.000000\n",
      "25%        -1.162288      -1.174820       0.130359      59.450441\n",
      "50%         0.009424      -0.009482       2.484236      94.925613\n",
      "75%         1.158535       1.163678       4.858794     130.595027\n",
      "max         7.238262       7.844801      16.739402     190.029838\n"
     ]
    }
   ],
   "source": [
    "# Imprimimos la información de cada dataframe y su descripción\n",
    "\n",
    "print(data_0.info())\n",
    "print(data_0.describe())\n",
    "print()\n",
    "\n",
    "print(data_1.info())\n",
    "print(data_1.describe())\n",
    "print()\n",
    "\n",
    "print(data_2.info())\n",
    "print(data_2.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Los DataFrame no tienen valores nulos, al analizar la media de la columna 'product' nos podemos dar cuenta que en el df data_1 la media es mucho menor que en los otros 2, en conclusión tiene menos petroleo en promedio que la otras 2 regiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               f0        f1        f2   product\n",
      "f0       1.000000 -0.440723 -0.003153  0.143536\n",
      "f1      -0.440723  1.000000  0.001724 -0.192356\n",
      "f2      -0.003153  0.001724  1.000000  0.483663\n",
      "product  0.143536 -0.192356  0.483663  1.000000\n",
      "\n",
      "               f0        f1        f2   product\n",
      "f0       1.000000  0.182287 -0.001777 -0.030491\n",
      "f1       0.182287  1.000000 -0.002595 -0.010155\n",
      "f2      -0.001777 -0.002595  1.000000  0.999397\n",
      "product -0.030491 -0.010155  0.999397  1.000000\n",
      "\n",
      "               f0        f1        f2   product\n",
      "f0       1.000000  0.000528 -0.000448 -0.001987\n",
      "f1       0.000528  1.000000  0.000779 -0.001012\n",
      "f2      -0.000448  0.000779  1.000000  0.445871\n",
      "product -0.001987 -0.001012  0.445871  1.000000\n"
     ]
    }
   ],
   "source": [
    "print(data_0.drop(columns=['id']).corr())\n",
    "print()\n",
    "print(data_1.drop(columns=['id']).corr())\n",
    "print()\n",
    "print(data_2.drop(columns=['id']).corr())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Al parecer la columna que más tiene relación con la columna 'product' es 'f2', teniendo la mayor correlación para las 3 regiones, pero con una casi perfecta en la región 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar y probar el modelo en cada región"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos la columna 'id' de cada dataframe ya que no es necesaria para el análisis\n",
    "\n",
    "data_0 = data_0.drop(columns=['id'])\n",
    "data_1 = data_1.drop(columns=['id'])\n",
    "data_2 = data_2.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000, 3)\n",
      "(25000, 3)\n"
     ]
    }
   ],
   "source": [
    "# Dividimos los datos en entrenamiento (75%) y validación (25%)\n",
    "\n",
    "features_0 = data_0.drop(columns=['product'])\n",
    "target_0 = data_0['product']\n",
    "\n",
    "features_train_0, features_valid_0, target_train_0, target_valid_0 = train_test_split(features_0, target_0, test_size=0.25, random_state=12345)\n",
    "\n",
    "# Verificamos los tamaños de los conjuntos de datos\n",
    "\n",
    "print(features_train_0.shape)\n",
    "print(features_valid_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       predictions      target\n",
      "71751    95.894952   10.038645\n",
      "80493    77.572583  114.551489\n",
      "2655     77.892640  132.603635\n",
      "53233    90.175134  169.072125\n",
      "91141    70.510088  122.325180\n",
      "\n",
      "Volumen medio de reservas predicho (Región 0): 92.59256778438035\n",
      "\n",
      "RMSE (Región 0): 37.5794217150813\n"
     ]
    }
   ],
   "source": [
    "# Creamos el modelo de regresión lineal y lo entrenamos con los datos de entrenamiento\n",
    "\n",
    "model_0 = LinearRegression()\n",
    "model_0.fit(features_train_0, target_train_0)\n",
    "predictions_valid_0 = model_0.predict(features_valid_0)\n",
    "\n",
    "# Guardamos las predicciones y los valores reales en un dataframe\n",
    "\n",
    "validation_results_0 = pd.DataFrame({'predictions': predictions_valid_0, 'target': target_valid_0})\n",
    "\n",
    "print(validation_results_0.head())\n",
    "\n",
    "# Volumen medio de reservas predicho en la región 0\n",
    "\n",
    "mean_predicted_volume_0 = validation_results_0['predictions'].mean()\n",
    "print()\n",
    "print('Volumen medio de reservas predicho (Región 0):', mean_predicted_volume_0)\n",
    "\n",
    "# Calculamos el RMSE del modelo\n",
    "\n",
    "rmse_0 = mean_squared_error(validation_results_0['target'], validation_results_0['predictions']) ** 0.5\n",
    "print()\n",
    "print('RMSE (Región 0):', rmse_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### El modelo predijo un volumen medio de reservas de 92.59 y tuvo un RMSE de 37.57, mientras más bajo sea el RMSE, mejor será la capacidad del modelo para predecir las reservas de petróleo en nuevos pozos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colocamos los pasos previos en funciones\n",
    "\n",
    "def split_data(data, target_column, test_size=0.25, random_state=12345):\n",
    "    features = data.drop(columns=[target_column])\n",
    "    target = data[target_column]\n",
    "    features_train, features_valid, target_train, target_valid = train_test_split(features, target, test_size=test_size, random_state=random_state)\n",
    "    return features_train, features_valid, target_train, target_valid\n",
    "\n",
    "def train_and_predict(features_train, target_train, features_valid):\n",
    "    model = LinearRegression()\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions_valid = model.predict(features_valid)\n",
    "    return predictions_valid\n",
    "\n",
    "def calculate_rmse(target_valid, predictions_valid):\n",
    "    return mean_squared_error(target_valid, predictions_valid) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       predictions     target\n",
      "71751    82.663314  80.859783\n",
      "80493    54.431786  53.906522\n",
      "2655     29.748760  30.132364\n",
      "53233    53.552133  53.906522\n",
      "91141     1.243856   0.000000\n",
      "\n",
      "Volumen medio de reservas predicho (Región 1): 68.728546895446\n",
      "\n",
      "RMSE (Región 1): 0.8930992867756169\n"
     ]
    }
   ],
   "source": [
    "# Aplicamos las funciones a los datos de la región 1\n",
    "\n",
    "features_train_1, features_valid_1, target_train_1, target_valid_1 = split_data(data_1, 'product')\n",
    "\n",
    "predictions_valid_1 = train_and_predict(features_train_1, target_train_1, features_valid_1)\n",
    "\n",
    "validation_results_1 = pd.DataFrame({'predictions': predictions_valid_1, 'target': target_valid_1})\n",
    "\n",
    "mean_predicted_volume_1 = validation_results_1['predictions'].mean()\n",
    "\n",
    "rmse_1 = calculate_rmse(validation_results_1['target'], validation_results_1['predictions'])\n",
    "\n",
    "print(validation_results_1.head())\n",
    "print()\n",
    "print('Volumen medio de reservas predicho (Región 1):', mean_predicted_volume_1)\n",
    "print()\n",
    "print('RMSE (Región 1):', rmse_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Los resultados muestran que el modelo en la Región 1 tiene un volumen medio de reservas predicho de 68.73 y un RMSE de 0.89, lo que indica que las predicciones están muy cerca de los valores reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       predictions      target\n",
      "71751    93.599633   61.212375\n",
      "80493    75.105159   41.850118\n",
      "2655     90.066809   57.776581\n",
      "53233   105.162375  100.053761\n",
      "91141   115.303310  109.897122\n",
      "\n",
      "Volumen medio de reservas predicho (Región 2): 94.96504596800492\n",
      "\n",
      "RMSE (Región 2): 40.02970873393434\n"
     ]
    }
   ],
   "source": [
    "# Aplicamos las funciones a los datos de la región 2\n",
    "\n",
    "features_train_2, features_valid_2, target_train_2, target_valid_2 = split_data(data_2, 'product')\n",
    "\n",
    "predictions_valid_2 = train_and_predict(features_train_2, target_train_2, features_valid_2)\n",
    "\n",
    "validation_results_2 = pd.DataFrame({'predictions': predictions_valid_2, 'target': target_valid_2})\n",
    "\n",
    "mean_predicted_volume_2 = validation_results_2['predictions'].mean()\n",
    "\n",
    "rmse_2 = calculate_rmse(validation_results_2['target'], validation_results_2['predictions'])\n",
    "\n",
    "print(validation_results_2.head())\n",
    "print()\n",
    "print('Volumen medio de reservas predicho (Región 2):', mean_predicted_volume_2)\n",
    "print()\n",
    "print('RMSE (Región 2):', rmse_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### La región 2 tiene el mayor volumen medio de reservas predicho 94.97, lo que sugiere que es la mejor en términos de producción esperada, sin embargo también tiene el mayor RMSE 40.03, lo que indica que el modelo tiene más variabilidad en sus predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcular las ganancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unidades necesarias para evitar pérdidas: 111.11111111111111\n",
      "Media de reservas predichas - Región 0: 92.59256778438035\n",
      "Media de reservas predichas - Región 1: 68.728546895446\n",
      "Media de reservas predichas - Región 2: 94.96504596800492\n"
     ]
    }
   ],
   "source": [
    "# Calculamos el presupuesto necesario para evitar pérdidas\n",
    "\n",
    "budget = 100_000_000\n",
    "wells = 200\n",
    "price = 4500 \n",
    "break_even = budget / (wells * price)\n",
    "\n",
    "\n",
    "print(\"Unidades necesarias para evitar pérdidas:\", break_even)\n",
    "print(\"Media de reservas predichas - Región 0:\", mean_predicted_volume_0)\n",
    "print(\"Media de reservas predichas - Región 1:\", mean_predicted_volume_1)\n",
    "print(\"Media de reservas predichas - Región 2:\", mean_predicted_volume_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### La media de todas las regiones está por debajo de 111.1 unidades, hay un alto riesgo de perdidas. La región con mayor media de reservas tiene posibilidades de ser rentable, pero aún debemos considerar la variabilidad con bootstrapping, es crucial elegir los 200 mejores pozos de los 500 disponibles para mejorar la rentabilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcular la ganancia de un conjunto de pozos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profit Region 0: 33208260.43\n",
      "Profit Region 1: 24150866.97\n",
      "Profit Region 2: 27103499.64\n"
     ]
    }
   ],
   "source": [
    "# Definimos una función para calcular la ganancia\n",
    "\n",
    "def calculate_profit(target, predictions, num_of_wells=200, budget=100_000_000, price=4500):\n",
    "    predictions_series = pd.Series(predictions, index=target.index)\n",
    "    \n",
    "    # Seleccionar los 200 pozos con mayores predicciones\n",
    "    top_wells = target.loc[predictions_series.nlargest(num_of_wells).index]\n",
    "\n",
    "    # Calcular la ganancia total\n",
    "    profit = (top_wells.sum() * price) - budget\n",
    "    \n",
    "    return round(profit, 2)\n",
    "\n",
    "# Calculamos la ganancia para cada región\n",
    "profit_0 = calculate_profit(target_valid_0, predictions_valid_0)\n",
    "profit_1 = calculate_profit(target_valid_1, predictions_valid_1)\n",
    "profit_2 = calculate_profit(target_valid_2, predictions_valid_2)\n",
    "\n",
    "print(f\"Profit Region 0: {profit_0}\")\n",
    "print(f\"Profit Region 1: {profit_1}\")\n",
    "print(f\"Profit Region 2: {profit_2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Despues de analizar las ganacias estimadas para cada región se recomienda desarrollar pozos petroleros en la Región 0, ya que prensenta la mayor ganancia esperada en comparación con las otras 2 regiones. Antes de tomar una decisión final, es importante verificar riesgo de pérdidas mediante una prueba bootstrap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcular riesgos y ganancias para cada región"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Región 0, profit promedio: 3807108.9070907477 percentil menor: -1269476.3803180228 percentil mayor: 8796139.67847796 riesgo de perdida: 0.072\n",
      "\n",
      "Región 1, profit promedio: 4482310.651477294 percentil menor: 708993.8493535467 percentil mayor: 8929852.497000607 riesgo de perdida: 0.014\n",
      "\n",
      "Región 2, profit promedio: 4027965.8717197105 percentil menor: -1436593.0684827077 percentil mayor: 9630261.544863084 riesgo de perdida: 0.071\n"
     ]
    }
   ],
   "source": [
    "# Creamos una función para realizar el bootstraping\n",
    "\n",
    "budget = 100_000_000\n",
    "wells = 200\n",
    "price = 4500 \n",
    "df_region_0 = pd.DataFrame({'pred': predictions_valid_0, 'real': target_valid_0})\n",
    "df_region_1 = pd.DataFrame({'pred': predictions_valid_1, 'real': target_valid_1})\n",
    "df_region_2 = pd.DataFrame({'pred': predictions_valid_2, 'real': target_valid_2})\n",
    "\n",
    "def calcular_profit(unidades):\n",
    "    \n",
    "    revenue = unidades * price  \n",
    "    profit = (revenue - budget) \n",
    "    return profit\n",
    "\n",
    "def bootstrap_profit(df_region, n_samples=1000):\n",
    "    np.random.seed(12345)  \n",
    "    values = []\n",
    "\n",
    "    for _ in range(n_samples):\n",
    "        sample_df = df_region.sample(n=500, replace=False)\n",
    "        best_200_sample = sample_df.sort_values(by='pred', ascending=False).head(200)\n",
    "        unidades_sample = best_200_sample['real'].sum() \n",
    "        profit = calcular_profit(unidades_sample)  \n",
    "        values.append(profit)\n",
    "\n",
    "    values = np.array(values)  \n",
    "    profit_promedio = values.mean()  \n",
    "    percentil_menor = np.percentile(values, 2.5)  \n",
    "    percentil_mayor = np.percentile(values, 97.5)  \n",
    "    riesgo_perdida = (values < 0).mean()  \n",
    "\n",
    "    return profit_promedio, percentil_menor, percentil_mayor, riesgo_perdida\n",
    "\n",
    "# Calcular bootstrapping para cada región\n",
    "mean_0, lower_0, upper_0, risk_0 = bootstrap_profit(df_region_0)\n",
    "print(\"Región 0,\", \"profit promedio:\", mean_0, \"percentil menor:\", lower_0, \"percentil mayor:\", upper_0, \"riesgo de perdida:\", risk_0)\n",
    "print()\n",
    "mean_1, lower_1, upper_1, risk_1 = bootstrap_profit(df_region_1)\n",
    "print(\"Región 1,\", \"profit promedio:\", mean_1, \"percentil menor:\", lower_1, \"percentil mayor:\", upper_1, \"riesgo de perdida:\", risk_1)\n",
    "print()\n",
    "mean_2, lower_2, upper_2, risk_2 = bootstrap_profit(df_region_2)\n",
    "print(\"Región 2,\", \"profit promedio:\", mean_2, \"percentil menor:\", lower_2, \"percentil mayor:\", upper_2, \"riesgo de perdida:\", risk_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### La región con el menor riesgo de perdidas es la región 1, lo que significa que es la mejor región para invertir ya que tiene el mayor profit promedio de las 3 regiones\n",
    "\n",
    "##### En comparación, las Región 0 y Región 2 tienen percentiles menores negativos lo que significa que podrían enfrentar pérdidas\n",
    "\n",
    "##### En el análisis previo, la Región 0 fue la preferida, pero ahora, aplicando la técnica del bootstrapping, la elección cambió, siendo la Región 1 la mejor opción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En este proyecto, analizamos tres posibles regiones para el desarrollo de pozos petroleros. Usamos diferentes métodos, como las predicciones de volumen de reservas y la técnica del bootstrapping, para entender cuál de ellas podría generar más beneficios. Aunque todas las regiones tienen un riesgo de pérdidas, la Región 2 resultó ser la mejor opción, ya que aunque no generará ganancias, sus pérdidas serían menores comparadas con las demás. Por lo tanto, después de evaluar todos los datos, la Región 2 es la que presenta el menor impacto negativo y, por lo tanto, es la más recomendable para desarrollar los pozos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
