{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning: Smart o Ultra?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La compañía móvil Megaline no está satisfecha al ver que muchos de sus clientes utilizan planes heredados. Quieren desarrollar un modelo que pueda analizar el comportamiento de los clientes y recomendar uno de los nuevos planes de Megaline: Smart o Ultra. En este proyecto, se ha evaluado el desempeño de diferentes modelos de clasificación para predecir la variable objetivo a partir de un conjunto de datos. El objetivo principal ha sido desarrollar un modelo con la mayor exactitud posible, superando el umbral de 0.75 en los conjuntos de validación y prueba. Para lograrlo, se probaron tres modelos: RandomForestClassifier, DecisionTreeClassifier y LogisticRegression, ajustando diversos hiperparámetros y evaluando la exactitud en los conjuntos de entrenamiento, validación y prueba. El análisis se centra en la comparación del rendimiento de cada modelo, destacando cuál cumple mejor con los requisitos del proyecto y cuál se adapta de forma óptima a los datos disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos las librerías\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos el dataset\n",
    "\n",
    "df = pd.read_csv('users_behavior.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n",
      "None\n",
      "\n",
      "   calls  minutes  messages   mb_used  is_ultra\n",
      "0   40.0   311.90      83.0  19915.42         0\n",
      "1   85.0   516.75      56.0  22696.96         0\n",
      "2   77.0   467.66      86.0  21060.45         0\n",
      "3  106.0   745.53      81.0   8437.39         1\n",
      "4   66.0   418.74       1.0  14502.75         0\n",
      "5   58.0   344.56      21.0  15823.37         0\n",
      "6   57.0   431.64      20.0   3738.90         1\n",
      "7   15.0   132.40       6.0  21911.60         0\n",
      "8    7.0    43.39       3.0   2538.67         1\n",
      "9   90.0   665.41      38.0  17358.61         0\n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "print()\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentamos los datos en un conjunto de entrenamiento, uno de validación y uno de prueba\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.25, random_state=54321)\n",
    "df_train, df_valid = train_test_split(df_train, test_size=0.25, random_state=54321)\n",
    "\n",
    "features_train = df_train.drop(['is_ultra'], axis=1)\n",
    "target_train = df_train['is_ultra']\n",
    "\n",
    "features_valid = df_valid.drop(['is_ultra'], axis=1)\n",
    "target_valid = df_valid['is_ultra']\n",
    "\n",
    "features_test = df_test.drop(['is_ultra'], axis=1)\n",
    "target_test = df_test['is_ultra']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1 :  0.7661691542288557\n",
      "max_depth = 2 :  0.802653399668325\n",
      "max_depth = 3 :  0.8076285240464345\n",
      "max_depth = 4 :  0.8175787728026535\n",
      "max_depth = 5 :  0.8109452736318408\n",
      "Exactitud en el conjunto de prueba: 0.7810945273631841\n"
     ]
    }
   ],
   "source": [
    "# Investigamos la calidad de diferentes modelos cambiando los hiperparámetros\n",
    "# Creamos un bucle para max_depth de 1 a 5\n",
    "\n",
    "for depth in range(1, 6):\n",
    "    model = DecisionTreeClassifier(random_state=54321, max_depth=depth)\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions = model.predict(features_valid)\n",
    "    accuracy = accuracy_score(target_valid, predictions)\n",
    "    print(\"max_depth =\", depth, \": \", accuracy)\n",
    "\n",
    "# Predecimos el conjunto de prueba con el mejor modelo\n",
    "model = DecisionTreeClassifier(random_state=54321, max_depth=4)\n",
    "model.fit(features_train, target_train)\n",
    "predictions_test = model.predict(features_test)\n",
    "\n",
    "# Calculamos la exactitud del modelo\n",
    "accuracy_test = accuracy_score(target_test, predictions_test)\n",
    "print(\"Exactitud en el conjunto de prueba:\", accuracy_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### En las pruebas de validación el modelo de arbol de decisión deja de mejorar a partir de la profundidad 4 alcanzado un 0.8175 de exactitud y en el conjunto de prueba la exactitud bajó a 0.7810"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La exactitud del mejor modelo en el conjunto de validación (n_estimators = 12): 0.8192371475953566\n",
      "Exactitud en el conjunto de prueba: 0.7761194029850746\n"
     ]
    }
   ],
   "source": [
    "# Investigamos la calidad de diferentes modelos cambiando los hiperparámetros\n",
    "\n",
    "best_score = 0\n",
    "best_est = 0\n",
    "\n",
    "for est in range(10, 101):\n",
    "    model = RandomForestClassifier(random_state=54321, n_estimators=est)\n",
    "    model.fit(features_train, target_train)\n",
    "    score = model.score(features_valid, target_valid)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_est = est\n",
    "\n",
    "print('La exactitud del mejor modelo en el conjunto de validación (n_estimators = {}): {}'.format(best_est, best_score))\n",
    "\n",
    "# Predecimos el conjunto de prueba con el mejor modelo\n",
    "model = RandomForestClassifier(random_state=54321, n_estimators=12)\n",
    "model.fit(features_train, target_train)\n",
    "predictions_test = model.predict(features_test)\n",
    "print('Exactitud en el conjunto de prueba:', accuracy_score(target_test, predictions_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### En este modelo random forest con el conjunto de validación el valor de n_estimators = 12 resultó ser el mejor dando la mejor exactitud de 0.8192 y la exactitud en el conjunto de prueba fue de 0.7761 un poco por debajo de la primera prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del modelo de regresión logística en el conjunto de entrenamiento: 0.7122302158273381\n",
      "Accuracy del modelo de regresión logística en el conjunto de validación: 0.7313432835820896\n",
      "Accuracy del modelo de regresión logística en el conjunto de prueba: 0.6965174129353234\n"
     ]
    }
   ],
   "source": [
    "# Investigamos la calidad de diferentes modelos cambiando los hiperparámetros\n",
    "\n",
    "model = LogisticRegression(random_state=54321, solver='liblinear')\n",
    "model.fit(features_train, target_train)\n",
    "score_train = model.score(features_train, target_train)\n",
    "score_valid = model.score(features_valid, target_valid)\n",
    "score_test = model.score(features_test, target_test)\n",
    "\n",
    "print('Accuracy del modelo de regresión logística en el conjunto de entrenamiento:', score_train)\n",
    "print('Accuracy del modelo de regresión logística en el conjunto de validación:', score_valid)\n",
    "print('Accuracy del modelo de regresión logística en el conjunto de prueba:', score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### En el modelo de regresión logística la exactitud no cumple con el umbral minimo de 0.75 en ninguna de las pruebas, siendo un modelo no viable para nuestros objetivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El modelo con la mejor exactitud que pude crear fue el RandomForestClassifier, alcanzando una exactitud de 0.8192. Aunque su rendimiento disminuyó ligeramente en el conjunto de prueba, esto es completamente normal, ya que los datos de prueba son completamente desconocidos para el modelo. Por otro lado, el DecisionTreeClassifier mostró una menor exactitud en el conjunto de validación, pero superó al RandomForest en el conjunto de pruebas, aunque de manera muy ajustada. Finalmente, el modelo de LogisticRegression no cumplió con el umbral de 0.75 en ninguna de las pruebas, por lo que se considera no apto para los objetivos del proyecto."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
