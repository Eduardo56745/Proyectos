{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de Predicción con Gradiente en el Mercado de Coches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rusty Bargain es una tienda de coches de segunda mano que está desarrollando una aplicación para ayudar a los usuarios a conocer el valor de mercado de sus vehículos de manera rápida y sencilla. Para lograrlo, es necesario crear un modelo que pueda predecir este valor con precisión.\n",
    "\n",
    "### En este análisis, se han probado diferentes modelos de aprendizaje automático, como regresión lineal, árboles de decisión, bosque aleatorio y modelos basados en gradiente como XGBoost y LightGBM. El objetivo es encontrar el modelo que ofrezca las mejores predicciones, así como un tiempo de entrenamiento y predicción adecuado para la aplicación móvil.\n",
    "\n",
    "### Este estudio ayudará a Rusty Bargain a elegir el modelo más eficiente para mejorar la experiencia del usuario en su plataforma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerias necesarias\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "import catboost\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el dataset\n",
    "\n",
    "df = pd.read_csv('car_data.csv')\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 354369 entries, 0 to 354368\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   DateCrawled        354369 non-null  object\n",
      " 1   Price              354369 non-null  int64 \n",
      " 2   VehicleType        316879 non-null  object\n",
      " 3   RegistrationYear   354369 non-null  int64 \n",
      " 4   Gearbox            334536 non-null  object\n",
      " 5   Power              354369 non-null  int64 \n",
      " 6   Model              334664 non-null  object\n",
      " 7   Mileage            354369 non-null  int64 \n",
      " 8   RegistrationMonth  354369 non-null  int64 \n",
      " 9   FuelType           321474 non-null  object\n",
      " 10  Brand              354369 non-null  object\n",
      " 11  NotRepaired        283215 non-null  object\n",
      " 12  DateCreated        354369 non-null  object\n",
      " 13  NumberOfPictures   354369 non-null  int64 \n",
      " 14  PostalCode         354369 non-null  int64 \n",
      " 15  LastSeen           354369 non-null  object\n",
      "dtypes: int64(7), object(9)\n",
      "memory usage: 43.3+ MB\n",
      "None\n",
      "\n",
      "        DateCrawled  Price VehicleType  RegistrationYear Gearbox  Power  \\\n",
      "0  24/03/2016 11:52    480         NaN              1993  manual      0   \n",
      "1  24/03/2016 10:58  18300       coupe              2011  manual    190   \n",
      "2  14/03/2016 12:52   9800         suv              2004    auto    163   \n",
      "3  17/03/2016 16:54   1500       small              2001  manual     75   \n",
      "4  31/03/2016 17:25   3600       small              2008  manual     69   \n",
      "\n",
      "   Model  Mileage  RegistrationMonth  FuelType       Brand NotRepaired  \\\n",
      "0   golf   150000                  0    petrol  volkswagen         NaN   \n",
      "1    NaN   125000                  5  gasoline        audi         yes   \n",
      "2  grand   125000                  8  gasoline        jeep         NaN   \n",
      "3   golf   150000                  6    petrol  volkswagen          no   \n",
      "4  fabia    90000                  7  gasoline       skoda          no   \n",
      "\n",
      "        DateCreated  NumberOfPictures  PostalCode          LastSeen  \n",
      "0  24/03/2016 00:00                 0       70435  07/04/2016 03:16  \n",
      "1  24/03/2016 00:00                 0       66954  07/04/2016 01:46  \n",
      "2  14/03/2016 00:00                 0       90480  05/04/2016 12:47  \n",
      "3  17/03/2016 00:00                 0       91074  17/03/2016 17:40  \n",
      "4  31/03/2016 00:00                 0       60437  06/04/2016 10:17  \n"
     ]
    }
   ],
   "source": [
    "# Mostramos la informacion del dataset\n",
    "\n",
    "print(df.info())\n",
    "print()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunas columnas tienen valores faltantes, como VehicleType, Gearbox, Model, FuelType, NotRepaired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        DateCrawled  Price VehicleType  RegistrationYear Gearbox  Power  \\\n",
      "0  24/03/2016 11:52    480       sedan              1993  manual      0   \n",
      "1  24/03/2016 10:58  18300       coupe              2011  manual    190   \n",
      "2  14/03/2016 12:52   9800         suv              2004    auto    163   \n",
      "3  17/03/2016 16:54   1500       small              2001  manual     75   \n",
      "4  31/03/2016 17:25   3600       small              2008  manual     69   \n",
      "\n",
      "   Model  Mileage  RegistrationMonth  FuelType       Brand NotRepaired  \\\n",
      "0   golf   150000                  0    petrol  volkswagen          no   \n",
      "1   golf   125000                  5  gasoline        audi         yes   \n",
      "2  grand   125000                  8  gasoline        jeep          no   \n",
      "3   golf   150000                  6    petrol  volkswagen          no   \n",
      "4  fabia    90000                  7  gasoline       skoda          no   \n",
      "\n",
      "        DateCreated  NumberOfPictures  PostalCode          LastSeen  \n",
      "0  24/03/2016 00:00                 0       70435  07/04/2016 03:16  \n",
      "1  24/03/2016 00:00                 0       66954  07/04/2016 01:46  \n",
      "2  14/03/2016 00:00                 0       90480  05/04/2016 12:47  \n",
      "3  17/03/2016 00:00                 0       91074  17/03/2016 17:40  \n",
      "4  31/03/2016 00:00                 0       60437  06/04/2016 10:17  \n"
     ]
    }
   ],
   "source": [
    "# Rellenar los valores faltantes\n",
    "\n",
    "df['VehicleType'] = df['VehicleType'].fillna(df['VehicleType'].mode()[0])\n",
    "df['Gearbox'] = df['Gearbox'].fillna(df['Gearbox'].mode()[0])\n",
    "df['Model'] = df['Model'].fillna(df['Model'].mode()[0])\n",
    "df['FuelType'] = df['FuelType'].fillna(df['FuelType'].mode()[0])\n",
    "df['NotRepaired'] = df['NotRepaired'].fillna(df['NotRepaired'].mode()[0])\n",
    "\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 354369 entries, 0 to 354368\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   Price              354369 non-null  int64 \n",
      " 1   VehicleType        354369 non-null  object\n",
      " 2   RegistrationYear   354369 non-null  int64 \n",
      " 3   Gearbox            354369 non-null  object\n",
      " 4   Power              354369 non-null  int64 \n",
      " 5   Model              354369 non-null  object\n",
      " 6   Mileage            354369 non-null  int64 \n",
      " 7   RegistrationMonth  354369 non-null  int64 \n",
      " 8   FuelType           354369 non-null  object\n",
      " 9   Brand              354369 non-null  object\n",
      " 10  NotRepaired        354369 non-null  object\n",
      "dtypes: int64(5), object(6)\n",
      "memory usage: 29.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Eliminamos datos irrelevantes para el aprendizaje\n",
    "\n",
    "df = df.drop(['PostalCode', 'NumberOfPictures', 'DateCrawled', 'DateCreated', 'LastSeen'], axis=1)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos One Hot Encoding a todas las columnas categóricas\n",
    "\n",
    "df = pd.get_dummies(df, columns=['VehicleType', 'Gearbox', 'Model', 'FuelType', 'Brand', 'NotRepaired'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Price  RegistrationYear  Power  Mileage  RegistrationMonth  \\\n",
      "0    480              1993      0   150000                  0   \n",
      "1  18300              2011    190   125000                  5   \n",
      "2   9800              2004    163   125000                  8   \n",
      "3   1500              2001     75   150000                  6   \n",
      "4   3600              2008     69    90000                  7   \n",
      "\n",
      "   VehicleType_convertible  VehicleType_coupe  VehicleType_other  \\\n",
      "0                    False              False              False   \n",
      "1                    False               True              False   \n",
      "2                    False              False              False   \n",
      "3                    False              False              False   \n",
      "4                    False              False              False   \n",
      "\n",
      "   VehicleType_sedan  VehicleType_small  ...  Brand_skoda  Brand_smart  \\\n",
      "0               True              False  ...        False        False   \n",
      "1              False              False  ...        False        False   \n",
      "2              False              False  ...        False        False   \n",
      "3              False               True  ...        False        False   \n",
      "4              False               True  ...         True        False   \n",
      "\n",
      "   Brand_sonstige_autos  Brand_subaru  Brand_suzuki  Brand_toyota  \\\n",
      "0                 False         False         False         False   \n",
      "1                 False         False         False         False   \n",
      "2                 False         False         False         False   \n",
      "3                 False         False         False         False   \n",
      "4                 False         False         False         False   \n",
      "\n",
      "   Brand_trabant  Brand_volkswagen  Brand_volvo  NotRepaired_yes  \n",
      "0          False              True        False            False  \n",
      "1          False             False        False             True  \n",
      "2          False             False        False            False  \n",
      "3          False              True        False            False  \n",
      "4          False             False        False            False  \n",
      "\n",
      "[5 rows x 308 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora el DataFrame está bien estructurado para continuar con el modelo de Machine Learning, con las variables categóricas convertidad en columnas y las variables continuas permanecen en su formato original, además las fechas se mantienen como datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos los datos en entrenamiento y prueba\n",
    "\n",
    "X = df.drop('Price', axis=1)\n",
    "y = df['Price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de entremamiento = 3.60 segundos\n",
      "r2_score: 0.49\n",
      "RMSE: 3219.70\n"
     ]
    }
   ],
   "source": [
    "# Definimos el modelo de regresión lineal\n",
    "\n",
    "model = LinearRegression()\n",
    "start_time = time()\n",
    "model.fit(X_train, y_train)\n",
    "train_time = time() - start_time\n",
    "\n",
    "print(f'Tiempo de entremamiento = {train_time:.2f} segundos')\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'r2_score: {r2:.2f}')\n",
    "print(f'RMSE: {rmse:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo tuvo un tiempo de entranamiento de 3.60 segundos y un RMSE de 3219.70 indica que en promedio, las predicciones del modelo se desvían en alrededor de 3219 unidades de los valores reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de entremamiento = 6.29 segundos\n",
      "r2_score: 0.79\n",
      "RMSE: 2047.19\n"
     ]
    }
   ],
   "source": [
    "# Definimos el modelo de árbol de decisión\n",
    "\n",
    "model = DecisionTreeRegressor(max_depth=15, random_state=1234)\n",
    "start_time = time()\n",
    "model.fit(X_train, y_train)\n",
    "train_time = time() - start_time\n",
    "print(f'Tiempo de entremamiento = {train_time:.2f} segundos')\n",
    "y_pred = model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'r2_score: {r2:.2f}')\n",
    "print(f'RMSE: {rmse:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo de arbol de decisión tuvo un tiempo de entrenamiento de 6.25 segundos y un RMSE de 2047.19 lo cual fue un poco más bajo que en el modelo de regresión lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de entremamiento = 198.01 segundos\n",
      "r2_score: 0.83\n",
      "RMSE: 1848.19\n"
     ]
    }
   ],
   "source": [
    "# Definamos el modelo de bosque aleatorio\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=50, max_depth=15, random_state=1234)\n",
    "start_time = time()\n",
    "model.fit(X_train, y_train)\n",
    "train_time = time() - start_time\n",
    "print(f'Tiempo de entremamiento = {train_time:.2f} segundos')\n",
    "y_pred = model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'r2_score: {r2:.2f}')\n",
    "print(f'RMSE: {rmse:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo de bosque aleatorio tuvo un tiempo de entrenamiento de 198.01 segundos, siendo el que más se ha tardado y con bastante diferencia, pero tuvo el mejor RMSE con 1848.19."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.911444\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.554301\n",
      "[LightGBM] [Debug] init for col-wise cost 0.005444 seconds, init for row-wise cost 0.016076 seconds\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 953\n",
      "[LightGBM] [Info] Number of data points in the train set: 265776, number of used features: 291\n",
      "[LightGBM] [Info] Start training from score 4411.233366\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 6\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "\n",
      "Tiempo de entremamiento = 1.03 segundos\n",
      "r2_score: 0.82\n",
      "RMSE: 1939.59\n"
     ]
    }
   ],
   "source": [
    "# Definamos el modelo de LightGBM\n",
    "\n",
    "model_lgb = lgb.LGBMRegressor(n_estimators=50, max_depth=15, verbose=2, random_state=1234)\n",
    "start_time = time()\n",
    "model_lgb.fit(X_train, y_train)\n",
    "train_time = time() - start_time\n",
    "print()\n",
    "print(f'Tiempo de entremamiento = {train_time:.2f} segundos')\n",
    "y_pred = model_lgb.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'r2_score: {r2:.2f}')\n",
    "print(f'RMSE: {rmse:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tiempo de entrenamiento para el modelo de LightGBM fue de 0.96 segundos, lo cual es muy rápido considerando el tamaño del conjunto de datos y el RMSE fue de 1939.59, este valor no es el más bajo de todos los modelos pero si el que más rápido lo hace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de entremamiento = 6.79 segundos\n",
      "r2_score: 0.85\n",
      "RMSE: 1729.12\n"
     ]
    }
   ],
   "source": [
    "# Definamos el modelo de XGBoost\n",
    "\n",
    "model_xgb = XGBRegressor(n_estimators=50, max_depth=15, learning_rate=0.1, verbosity=2, random_state=1234)\n",
    "start_time = time()\n",
    "model_xgb.fit(X_train, y_train)\n",
    "train_time = time() - start_time\n",
    "print(f'Tiempo de entremamiento = {train_time:.2f} segundos')\n",
    "y_pred = model_xgb.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'r2_score: {r2:.2f}')\n",
    "print(f'RMSE: {rmse:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo de XGBoost está funcionando bastante bien, con un r2 de 0.85 y un RMSE de 1729.12, está logrando un buen balance entre precisión y desempeño, aunque el tiempo de entrenamiento no es lo más rápido comparado con otros modelos, aún siue siendo un tiempo razonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de entremamiento = 19.24 segundos\n",
      "R2 Score: 0.83\n",
      "RMSE: 1870.06\n"
     ]
    }
   ],
   "source": [
    "# Definamos el modelo de CatBoost\n",
    "\n",
    "model_cat = catboost.CatBoostRegressor(n_estimators=50, max_depth=15, learning_rate=0.1, verbose=0, random_state=1234)\n",
    "start_time = time()\n",
    "model_cat.fit(X_train, y_train)\n",
    "train_time = time() - start_time\n",
    "print(f'Tiempo de entremamiento = {train_time:.2f} segundos')\n",
    "y_pred = model_cat.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R2 Score: {r2:.2f}')\n",
    "print(f'RMSE: {rmse:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo de CatBoost también está mostrando buenos resultados, aunque con un R2 de 0.83 y un RMSE de 1870.08 es ligeramente inferior al desempeño de XGBoost, sin embargo su tiempo de entrenamiento es más alto comparado con otros modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el análisis de los modelos de predicción del valor de mercado de coches para Rusty Bargain, se probaron diferentes algoritmos:\n",
    "1. XGBoost resultó ser el mejor en cuanto a RMSE (1729.12) y R2 (0.85). Este modelo presentó la mayor precisión en las predicciones y una excelente capacidad de ajuste a los datos. Además, su tiempo de entrenamiento (6.79 segundos) es razonable.\n",
    "\n",
    "2. CatBoost también mostró buenos resultados con un R2 de 0.83 y un RMSE de 1870.06, siendo ligeramente menos preciso que XGBoost, pero aún así ofreciendo un buen desempeño.\n",
    "\n",
    "3. LightGBM presentó un RMSE de 1939.59, lo que lo hace competitivo, aunque con menor precisión en comparación con XGBoost.\n",
    "\n",
    "4. Regresión Lineal tuvo un RMSE de 3219.70, el valor más alto entre todos los modelos. Esto indica que la regresión lineal tiene una menor capacidad para ajustar bien los datos en comparación con los modelos basados en árboles de decisión y potenciación del gradiente.\n",
    "\n",
    "En resumen, XGBoost es la mejor opción para Rusty Bargain en términos de precisión y velocidad de predicción, mientras que la regresión lineal y el random forest no es tan efectiva debido a su menor capacidad de ajuste a los datos y tiempo de ejecución."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
